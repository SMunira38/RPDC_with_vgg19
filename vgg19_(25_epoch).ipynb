{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOBdpAlWZGG3ETKRHeY5E+Z",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SMunira38/RPDC_with_vgg19/blob/main/vgg19_(25_epoch).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Ju2ljTsVpAc",
        "outputId": "b406d18d-7622-464d-c6e2-b705ac7f7fc4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch.optim as optim\n",
        "from torchvision.models import vgg19\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "A31o6qKhV8zY"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define paths for the dataset\n",
        "data_dir = '/content/drive/MyDrive/Full Custom Data BRRI'\n",
        "batch_size = 32"
      ],
      "metadata": {
        "id": "VxkfDyqyWbmJ"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define data transformations\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])"
      ],
      "metadata": {
        "id": "qOWZftfuWi6v"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the entire dataset from Google Drive\n",
        "dataset = torchvision.datasets.ImageFolder(root=data_dir, transform=transform)"
      ],
      "metadata": {
        "id": "Uu98ghtjWlun"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the sizes of train and test sets\n",
        "train_size = int(0.7 * len(dataset))\n",
        "test_size = len(dataset) - train_size\n",
        "print(\"Train Size:\", train_size)\n",
        "print(\"Test Size:\", test_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QT-YPllSWpLG",
        "outputId": "bc90886a-5922-4c14-9bd6-7fab0bceb481"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Size: 1120\n",
            "Test Size: 480\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the dataset into train and test sets\n",
        "train_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, test_size])\n",
        "\n",
        "# Create data loaders for train and test sets\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
      ],
      "metadata": {
        "id": "rIv1Jt_1WsJJ"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes = len(dataset.classes)\n",
        "print(\"Number of classes: \", num_classes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RHEclHQ1W04p",
        "outputId": "94343149-a3c1-4969-e873-8cd443250181"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of classes:  8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the pre-trained VGG19 model and modify it for your classification task\n",
        "\n",
        "model = vgg19(pretrained=True)\n",
        "model.classifier[6] = nn.Linear(4096, num_classes)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OvDPU0V8W3rX",
        "outputId": "d26631cd-7138-46d2-edc5-4a424c71ac98"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG19_Weights.IMAGENET1K_V1`. You can also use `weights=VGG19_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/vgg19-dcbb9e9d.pth\" to /root/.cache/torch/hub/checkpoints/vgg19-dcbb9e9d.pth\n",
            "100%|██████████| 548M/548M [00:06<00:00, 85.8MB/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "VGG(\n",
              "  (features): Sequential(\n",
              "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (3): ReLU(inplace=True)\n",
              "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (6): ReLU(inplace=True)\n",
              "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (8): ReLU(inplace=True)\n",
              "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (11): ReLU(inplace=True)\n",
              "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (13): ReLU(inplace=True)\n",
              "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (15): ReLU(inplace=True)\n",
              "    (16): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (17): ReLU(inplace=True)\n",
              "    (18): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (19): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (20): ReLU(inplace=True)\n",
              "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (22): ReLU(inplace=True)\n",
              "    (23): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (24): ReLU(inplace=True)\n",
              "    (25): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (26): ReLU(inplace=True)\n",
              "    (27): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (29): ReLU(inplace=True)\n",
              "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (31): ReLU(inplace=True)\n",
              "    (32): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (33): ReLU(inplace=True)\n",
              "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (35): ReLU(inplace=True)\n",
              "    (36): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
              "  (classifier): Sequential(\n",
              "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): Dropout(p=0.5, inplace=False)\n",
              "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
              "    (4): ReLU(inplace=True)\n",
              "    (5): Dropout(p=0.5, inplace=False)\n",
              "    (6): Linear(in_features=4096, out_features=8, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)"
      ],
      "metadata": {
        "id": "DlO2i-PVW_fq"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training loop\n",
        "num_epochs = 25\n",
        "train_losses = []\n",
        "train_accuracies = []\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct_predictions_train = 0\n",
        "    total_samples_train = 0\n",
        "\n",
        "    for images, labels in train_loader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total_samples_train += labels.size(0)\n",
        "        correct_predictions_train += (predicted == labels).sum().item()\n",
        "\n",
        "    train_losses.append(running_loss / len(train_loader))\n",
        "    train_accuracy = correct_predictions_train / total_samples_train\n",
        "    train_accuracies.append(train_accuracy)\n",
        "\n",
        "    print(f\"Epoch [{epoch+1}/{num_epochs}] - Loss: {train_losses[-1]} - Training Accuracy: {train_accuracy*100:.2f}%\")\n",
        "\n",
        "print(\"Finished Training\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6q_dFskVXD29",
        "outputId": "5f87fa84-832c-44cf-d1c1-aba82aed5488"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/25] - Loss: 1.1018008078847612 - Training Accuracy: 62.95%\n",
            "Epoch [2/25] - Loss: 0.5238608224051339 - Training Accuracy: 82.32%\n",
            "Epoch [3/25] - Loss: 0.26409627412046704 - Training Accuracy: 90.62%\n",
            "Epoch [4/25] - Loss: 0.16683987535403244 - Training Accuracy: 93.93%\n",
            "Epoch [5/25] - Loss: 0.15533917918801307 - Training Accuracy: 95.18%\n",
            "Epoch [6/25] - Loss: 0.1502032042081867 - Training Accuracy: 95.45%\n",
            "Epoch [7/25] - Loss: 0.03189875607910965 - Training Accuracy: 98.93%\n",
            "Epoch [8/25] - Loss: 0.026567689191350448 - Training Accuracy: 98.93%\n",
            "Epoch [9/25] - Loss: 0.10305454516118126 - Training Accuracy: 96.43%\n",
            "Epoch [10/25] - Loss: 0.12551375904918782 - Training Accuracy: 95.89%\n",
            "Epoch [11/25] - Loss: 0.05744576346395271 - Training Accuracy: 98.12%\n",
            "Epoch [12/25] - Loss: 0.013770555759713586 - Training Accuracy: 99.73%\n",
            "Epoch [13/25] - Loss: 0.01146274450501161 - Training Accuracy: 99.73%\n",
            "Epoch [14/25] - Loss: 0.005364491200556845 - Training Accuracy: 99.91%\n",
            "Epoch [15/25] - Loss: 0.002519414451983591 - Training Accuracy: 100.00%\n",
            "Epoch [16/25] - Loss: 0.001025143741987579 - Training Accuracy: 100.00%\n",
            "Epoch [17/25] - Loss: 0.0006525430511309033 - Training Accuracy: 100.00%\n",
            "Epoch [18/25] - Loss: 0.0004957065432660913 - Training Accuracy: 100.00%\n",
            "Epoch [19/25] - Loss: 0.00035445252617916724 - Training Accuracy: 100.00%\n",
            "Epoch [20/25] - Loss: 0.0004405010947916058 - Training Accuracy: 100.00%\n",
            "Epoch [21/25] - Loss: 0.00027648360446619336 - Training Accuracy: 100.00%\n",
            "Epoch [22/25] - Loss: 0.00022004708581724636 - Training Accuracy: 100.00%\n",
            "Epoch [23/25] - Loss: 0.00036827248259214685 - Training Accuracy: 100.00%\n",
            "Epoch [24/25] - Loss: 0.0002014946501796138 - Training Accuracy: 100.00%\n",
            "Epoch [25/25] - Loss: 0.0004142801774313349 - Training Accuracy: 100.00%\n",
            "Finished Training\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "I4rdlubgy43X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Testing loop\n",
        "test_accuracies = []\n",
        "\n",
        "model.eval()\n",
        "correct_predictions_test = 0\n",
        "total_samples_test = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "        total_samples_test += labels.size(0)\n",
        "        correct_predictions_test += (predicted == labels).sum().item()\n",
        "\n",
        "test_accuracy = correct_predictions_test / total_samples_test\n",
        "test_accuracies.append(test_accuracy)\n",
        "print(f\"Testing Accuracy: {test_accuracy*100:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UIOQIgo2XKnr",
        "outputId": "5501c89e-ed11-4688-a4d6-5ec7685106fb"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing Accuracy: 93.54%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cJZUqUAIXXn9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}